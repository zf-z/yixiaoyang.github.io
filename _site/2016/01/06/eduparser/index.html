<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>[Python] 一个抓取985/211大学院系里教师信息的爬虫小框架</title>
  <meta name="description" content="简介">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="/2016/01/06/eduparser/">
  <link rel="alternate" type="application/rss+xml" title="Leon's Blog" href="/feed.xml" />
  <link rel="stylesheet" type="text/css" href="http://apps.bdimg.com/libs/bootstrap/3.3.0/css/bootstrap.min.css">
  <link rel="stylesheet" type="text/css" href="/css/custom.css">
  <!--<link rel="stylesheet" type="text/css" href="/css/_syntax-highlighting.css">-->
  <!-- 返回顶部 -->
  <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">
  <script type="text/javascript" src="http://apps.bdimg.com/libs/jquery/2.1.1/jquery.min.js"></script>
  <script type="text/javascript" src="http://apps.bdimg.com/libs/bootstrap/3.3.0/js/bootstrap.min.js"></script>
  <script type="text/javascript" src="/js/index.js"></script>
  <link rel="stylesheet" type="text/css" href="http://apps.bdimg.com/libs/highlight.js/8.6/styles/magula.min.css">
  <script type="text/javascript" src="http://apps.bdimg.com/libs/highlight.js/8.4/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">Leon's Blog</a>
    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/bak/2015-12-25-Gentoo-seven-steps-to-upgrade/">Gentoo seven steps to upgrade</a>
          
        
          
          <a class="page-link" href="/bak/2016-03-10-WeeChat-usage.md.bak">[工具] WeeChat/IRC 存活指南</a>
          
        
          
        
          
          <a class="page-link" href="/AboutMe/">关于我</a>
          
        
          
        
          
        
          
        
          
          <a class="page-link" href="/message/">留言板</a>
          
        
      </div>
   </nav>
 </div>

  <HR style="FILTER: alpha(opacity=100,finishopacity=0,style=3)" width="100%" color=#987cb9 SIZE=3>
</header>


    <div class="page-content">
      <div class="wrapper">
        <div class="post main_post">

  <header class="post-header">
    <h1 class="post-title">[Python] 一个抓取985/211大学院系里教师信息的爬虫小框架</h1>
  </header>


  <div class="tags_div">
  
	
	  <span class="tags_span">Python</span>
	
  
  <span class="post-meta">2016-01-06 • leon</span>
 </div>


  <article class="post-content">
    <h3>简介</h3>

<p>目标是尽可能自动抓取目标大学、所需院系的在职教师名单和详细信息（主要是联系方式，简历等），结果生成格式化csv文件，包含内容包括姓名、英文名、职称、邮件、电话、部门、个人网站、电话、研究方向等。最大的问题在于各大学校院系的网站千奇百怪，格式不尽相同，工作量大。</p>

<p>思路：爬虫+解析器+存取器</p>

<h3>依赖</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>python 2.7.10
beautifulsoup4==4.4.1
lxml==3.4.4（remove）
requests==2.8.1
Ghost.py-0.2.3
python-imaging
pytesseract
tesseract-ocr（图像识别）
wand(imageMagic的绑定)
</code></pre>
</div>

<h3>其他库</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>ImageMagic
media-libs/leptonica
app-text/tesseract-3.04.00-r2::gentoo（需要自行下载源码编译training工具）
</code></pre>
</div>

<h3>OCR训练工具</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>jTessBoxEditor
</code></pre>
</div>

<h3>基本使用</h3>

<p>我只是写了一个简单的架子，功能：</p>

<ol>
  <li>
    <p>解析hao123的211/985名单</p>
  </li>
  <li>
    <p>数据 《=》csv/json相互转化</p>
  </li>
  <li>
    <p>按照用户选择解析各个学校、学院的在职员工数据（模糊匹配职称、电子邮件、电话等等基本信息），并抓取简历保存在学院目录。</p>
  </li>
  <li>
    <p>按照设置规则文件抓取目标内容,规则内容如下：</p>

    <p><code class="highlighter-rouge">
     # 目标所在的区域的tag和attrs（属性）
     self.zone_tag = ''
     self.zone_attr = {}
     # 要抓取的目标标签tag
     self.tag_name = tag_name or ''
     # 要抓取的目标标签的递归父亲tag列表
     # &lt;span&gt;&lt;p&gt;
     #   &lt;a&gt;something&lt;/a&gt;
     #  &lt;/p&gt;&lt;/span&gt;
     # 如&lt;a&gt; tag的父亲列表为["p","span"]
     self.parents = []    
     # 1. 目标节点属性
     # {
     #   'class':true, true或者false表示是否含有此标签
     #   'width':'21%'，标签为具体值则表示仅当标签=值时抓取
     #   'class':['class1','class2'], 标签为列表时表示仅当标签值为列表中的值才成立。暂未用到
     # }
     self.attrs = {}
     # 2. 结果筛选，暂未用到
     self.select = []
</code></p>
  </li>
</ol>

<p>一般来说，找到合适的zone、目标的tag、属性就能找到要找的内容。</p>

<p>解析员工数据时，先编辑对应<strong>学校</strong>下面的json文件，在目标<strong>学院</strong>的json结构里添加抓取规则。然后在<strong>学院</strong>目录下定义MyHandler.py文件，写合适的解析脚本进行解析即可得到想要的数据。</p>

<p>由于每个学院的解析模式各不相同，所以需要在每个学院目录下自己实现两个方法：</p>

<ul>
  <li>handler：将找到的目标转化为员工数据实体</li>
  <li>profile_handler：保存简历正文到文件，模糊匹配员工数据并返回</li>
</ul>

<p>json中的主要数据结构如下所示：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>"__classname__": "Academy",     表示数据的类型，自动写好的
"__module__": "models",         表示类的模块，自动写好的
"departments": {                [*] 找到一个学院的所有教师名单的索引页面，并填写进去,这个页面将用来解析employee（在职员工）
                                格式为名字：网址
    "全职教员":"http://www.math.pku.edu.cn/static/quanzhijiaoyuan.html"
},
departmentsRule结构暂时不用管，没用到
"departmentsRule": {
    "__classname__": "ParseRule", 
    "__module__": "models", 
    "attrs": {}, 
    "parents": [], 
    "select": [], 
    "tag_name": "", 
    "zone_attr": {}, 
    "zone_tag": ""
}, 
"departmentsUrl": "",           没用到
"done": false,                  没用到
"employees": [],                没用到，自动生成，不用管
"eng_name": "www.math.pku.edu.cn", 自动解析生成学院的英文名字，不用管
"hasDepartments": false,            不用管
"name": "数学科学学院",               自动解析生成，不用管
"parser": null, 
"rule": {                       [*]Rule是你的重点，这是一个规则配置文件
    "__classname__": "ParseRule", 表示数据的类型，自动写好的
    "__module__": "models",       表示类的模块，自动写好的  
    "attrs": {},                  目标tag_name的属性，类似zone_attr
    "parents": [],              [*]这个也是重点，目标的父标签，用于缩小解析范围的
    "select": [],                忽略永不到                              
    "tag_name": "a",            [*]目标tag，这个也是重点    
    "zone_attr": {"id":"main"}, [*]目标tag的属性，这个也是重点，如<span class="nt">&lt;a</span> <span class="na">class=</span><span class="s">"link"</span><span class="nt">&gt;</span>中的class属性为link，所以规则为{"class":"link"}
    "zone_tag": "div"           [*]目标区域tag，这个也是重点，（标签，如<span class="nt">&lt;table&gt;</span>，<span class="nt">&lt;html&gt;</span>，<span class="nt">&lt;p&gt;</span>都是标签），zone用于缩小网站目标范围，过滤冗余信息
},

"sname": "math",                  学院简称
"url": "http://www.math.pku.edu.cn/",    学院主页，自动解析出来的
"web_engine": "urllib2"             一般用urllib2,对于特定的js网站，需要用selen
</code></pre>
</div>

<p>####菜单</p>

<div class="highlighter-rouge"><pre class="highlight"><code>menu0 = '''
q. 退出
p. 打印所有大学名单
1. 抓取211名单到json文件
2. 从json文件导入211名单
3. 构建输出目录
4. 测试抓取院系导航目录
5. 自动猜测并分析出学校的院系导航链接
6. 抓取院系的名称和主页
</code></pre>
</div>

<ol>
  <li>out目录下如果存在<code class="highlighter-rouge">china211.json</code>则将其大学目录数据导入。如果不存在，可运行<code class="highlighter-rouge">python run.py</code>选择菜单1从hao123抓取。</li>
  <li>编辑<code class="highlighter-rouge">china985.json</code>，删除不感兴趣的大学。如仅保留985+理工。</li>
  <li>运行</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code>    $ python run.py
    选择6菜单
    选择学校
    选择院系
    开始解析
</code></pre>
</div>

<h3>数据结构</h3>

<div class="highlighter-rouge"><pre class="highlight"><code>China211
collges + rule
academies
Department
employees
</code></pre>
</div>

<p>####Parser</p>

<p>Parser主要有两种，一种是SimpleAParser对于简单的链接+简历url正文的教师队伍介绍页面进行解析。一种是SimpleTableParser对表格式的教师队伍介绍页面进行解析。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>l_parsers = {
    "Parser": Parser,
    "Hao123_211_Parser": Hao123_211_Parser,
    "SimpleAParser": SimpleAParser,
    "AutoAcademyParser": AutoAcademyParser,
    "SimpleTableParser":SimpleTableParser
}
</code></pre>
</div>

<p>####Models</p>

<p>Models模块包含了相关数据的结构，如College，Academy，Employee类结构，同时提供obj2json和json2obj等串行化/实例化接口。</p>

<p>###浏览器和javascript支持</p>

<p>对于一些比较变态的主页（主要是javascript数据），使用selenium调用firefox获取数据</p>

<h3>反爬虫问题</h3>

<p>遇到过比较棘手的将邮件等信息用图片方式进行展示的情况，没办法，只能用的OCR方式进行图像文字识别，可能还需要自己训练数据。</p>

<h3>其他</h3>

<ol>
  <li>JSon”陷阱”<br />
 对于自定义类的json化，需要注意成员必须事先定义好。否则在dump时会出现<code class="highlighter-rouge">循环解析</code>的问题。</li>
  <li>BeautifulSoup解析器<br />
 社区推荐优先使用lxml，主要是速度较快。但是使用时发现有时解析不到目标，改为python自带的”html-parser”。后期将分析原因，或者向社区提交bug</li>
  <li>中英文名转换
 主要是中文转英文名，使用了pypinyin库</li>
</ol>

<h3>源代码</h3>

<p>github地址：https://github.com/yixiaoyang/EduParser/</p>

  </article>

</div>
<!--
<div>
<HR style="FILTER: alpha(opacity=100,finishopacity=0,style=3)" width="100%" color=#987cb9 SIZE=3>
<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
var disqus_shortname = 'leon-blog';

/* * * DON'T EDIT BELOW THIS LINE * * */
(function() {
var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();
</script>
</div>
-->



      </div>
    </div>

    <div id="top" data-toggle="tooltip" data-placement="left" title="Top">
      <a href="javascript:;">
        <div class="arrow"></div>
        <div class="stick"></div>
      </a>
    </div>
    
    <footer class="">
  <div class="container">
    <div class="row">
      <div class="col-md-12">
        <a href="mailto:leon_e@163.com"><span class="glyphicon glyphicon-envelope"></span> leon_e@163.com</a>
        <span class="point"> · </span>
        
          <a href="https://github.com/yixiaoyang">
            <span class="icon">
              <svg viewBox="0 0 16 16">
                <path fill="#aaa" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/>
              </svg>
            </span>
            Github
          </a>
          
          
          <span class="point"> · </span>
          <span><a href="/feed.xml">RSS</a></span>
          <span class="point"> · </span>
          <span>Embedded System, Linux, Python & Ruby</span>
          <span class="point"> · </span>
          <span class="point"> . </span>
      </div>
	  <div><span> <!--<a href="https://www.upyun.com/"><img src="http://upfiles.b0.upaiyun.com/logo/90x45.png" alt="UPYUN"></a>--></span></div>
    </div>
  </div>
</footer>

 </body> 
</html>
